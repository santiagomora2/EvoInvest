import streamlit as st
import streamlit_shadcn_ui as ui
import numpy as np

st.header('EvoInvest - Aprendizaje')

tab = ui.tabs(options=['Algoritmo Gen√©tico', 'Conceptos Financieros / F√≥rmulas', 'Prueba Algoritmo Gen√©tico'], default_value='Algoritmo Gen√©tico', key="tabs_learn")

with st.sidebar:

    st.page_link("app.py", label="Regresar a Inicio", icon="üè†")

    st.page_link("pages/popt.py", label="Genera Portafolios!", icon="üìà")

if tab == 'Algoritmo Gen√©tico':

    st.markdown('''#### ¬øQu√© es un Algoritmo Gen√©tico?
                
Un **algoritmo gen√©tico** (AG) es un m√©todo de optimizaci√≥n basado en la **teor√≠a de la evoluci√≥n** de Darwin. Su objetivo es "evolucionar" hacia la **mejor soluci√≥n** mediante iteraciones sucesivas. 
                
#### ¬øC√≥mo lo hace? ¬°Te cuento el proceso!

1. **Inicializaci√≥n**: Creamos una ‚Äúpoblaci√≥n‚Äù inicial de posibles soluciones (diferentes combinaciones de activos en el portafolio).

2. **Evaluaci√≥n**: Cada ‚Äúindividuo‚Äù (o soluci√≥n) se eval√∫a usando una **funci√≥n de aptitud** que mide qu√© tan bueno es. Aqu√≠, usamos una m√©trica llamada Sharpe Ratio.

3. **Selecci√≥n**: Se eligen las soluciones con mayor aptitud.

4. **Cruce y Mutaci√≥n**: Estas soluciones se "combinan" y "mutan" para formar nuevas soluciones, permitiendo **exploraci√≥n y diversidad**.

5. **Iteraci√≥n**: Repetimos este ciclo, y al pasar de generaciones, las soluciones se vuelven cada vez **mejores.**
                
#### Pero, ¬øsi tengo m√°s de un objetivo?
                
En problemas de optimizaci√≥n de portafolio, muchas veces no basta con solo **maximizar la rentabilidad** o **minimizar el riesgo**; queremos hacer **ambas cosas al mismo tiempo**. Aqu√≠ es donde entra la optimizaci√≥n **multiobjetivo**.

#### ¬øQu√© es la Optimizaci√≥n Multiobjetivo?
                
La optimizaci√≥n multiobjetivo busca soluciones que **equilibren** dos o m√°s objetivos **a la vez**. En este caso, queremos **maximizar los retornos y minimizar el riesgo** de nuestro portafolio. Como estos dos objetivos pueden entrar en conflicto, el algoritmo trata de encontrar un **balance √≥ptimo**.

#### Frente de Pareto
                
Un concepto clave en la optimizaci√≥n de portafolios es el **frente de Pareto**. Esta es una gr√°fica que muestra las **mejores combinaciones** de riesgo y retorno para un conjunto de activos. Los puntos en el frente representan **portafolios ‚Äúeficientes‚Äù** que ofrecen el m√°ximo retorno posible para un nivel de riesgo dado, o el riesgo m√≠nimo para un nivel de retorno.
''')

elif tab == 'Conceptos Financieros / F√≥rmulas':

    st.markdown('''
#### Retornos
                
Los retornos de cada stock se calculan de la siguiente manera:
                
$\mu_i = \ln{(v_t - v_{t-1})}$
                
* Donde:
    * $\mu_i$: Retorno esperado del stock $i$
    * $v_t$: Valor del stock en el tiempo $t$
    * $v_{t-1}$: Valor del stock en el tiempo $t-1$

Con los retornos de cada stock en cada d√≠a, se define una matriz de retornos $\Mu$.
                
#### Riesgo
                
El riesgo entre dos stocks diferentes se obtiene calculando la matriz de covarianza:
                
$\Sigma = \mathbb{Cov}(\Mu)$
                
* Donde:
    * $M$: matriz de retornos
    * $\Sigma$: Matriz de covarianza de $M$
    * $\Sigma_{i, j}$: covarianza (riesgo) entre el stock $i$ y el $j$
                
#### M√©tricas del portafolio
                
Una vez definidos los retornos y riesgos de cada stock, se usa el AG para optimizar los pesos de cada stock en el portafolio, utilizando las siguientes m√©tricas:
                
##### Retorno de inversi√≥n:
                
$ R = \sum_{i=n}^{n}w_i \mu_i$

* Donde:
    * $R$: Retorno de inversi√≥n del portafolio
    * $w_i$: Peso asociado al stock $i$
    * $\mu_i$: Retorno esperado del stock $i$

##### Riesgo asociado:

$ \sigma = W \Sigma W^T$

* Donde:
    * $\sigma$: Desviaci√≥n est√°ndar asociada al portafolio
    * $W$: Vector de pesos del portafolio
    * $\Sigma$: Matriz de covarianza de $\Mu$
                
##### Sharpe Ratio
                
$ {(\sum_{i=n}^{n}w_i \mu_i - r)}/{\sigma}$

* Donde:
    * $w_i$: Peso asociado al stock $i$
    * $\mu_i$: Retorno esperado del stock $i$
    * $r$: risk free rate (generalmente $r=0.02$)
    * $\sigma$ Desviaci√≥n est√°ndar asociada al portafolio
                
### Restricciones
                
Para optimizar los pesos de cada stock, mediante el Algoritmo Gen√©tico, definimos las siguientes restricciones:

* $\sum_{i=n}^{n}w_i = 1$
* $w_i \geq 0, i = 1, 2, \dots, n $

* Donde:
    * $w_i$: Peso asociado al stock $i$
                ''')
    
elif tab == 'Prueba Algoritmo Gen√©tico':

    st.markdown('''
#### Prueba el algoritmo gen√©tico!
                
En este **ejemplo** sencillo, introduce una palabra que el **algoritmo** deber√° **encontrar**. Ajusta los **par√°metros** del algoritmo y observa c√≥mo el **algoritmo** se acerca a la palabra en cada iteraci√≥n.

En este caso, la **funci√≥n de fitness** es el n√∫mero de letras que cada individuo comparte con la **palabra objetivo**.           
                
''')

    st.sidebar.header("Par√°metros del Algoritmo Gen√©tico")

    # Par√°metros del algoritmo gen√©tico
    target_word = st.sidebar.text_input("Palabra Objetivo", "GENETICA")
    population_size = st.sidebar.slider("Tama√±o de la Poblaci√≥n", 10, 200, 100)
    num_generations = st.sidebar.slider("N√∫mero de Generaciones", 1, 500, 100)
    mutation_rate = st.sidebar.slider("Tasa de Mutaci√≥n", 0.0, 1.0, 0.05)
    print_every = st.sidebar.number_input("Imprimir cada cu√°ntas generaciones", min_value=1, value=5, step=1)

    # Configuraciones iniciales
    target_word = target_word.upper()
    word_length = len(target_word)
    alphabet = list("ABCDEFGHIJKLMNOPQRSTUVWXYZ ")

    # Generar una poblaci√≥n inicial aleatoria
    def generate_population(size, word_length):
        return [''.join(np.random.choice(alphabet, word_length)) for _ in range(size)]

    # Funci√≥n de aptitud: mide cu√°ntos caracteres coinciden con el objetivo
    def fitness(individual, target_word):
        return sum(1 for a, b in zip(individual, target_word) if a == b)

    # Selecci√≥n de los mejores individuos
    def selection(population, target_word):
        fitness_scores = [fitness(ind, target_word) for ind in population]
        sorted_population = [ind for _, ind in sorted(zip(fitness_scores, population), reverse=True)]
        return sorted_population[:len(population) // 2]

    # Cruce: combina dos individuos
    def crossover(parent1, parent2):
        split_point = np.random.randint(1, len(parent1))
        child = parent1[:split_point] + parent2[split_point:]
        return child

    # Mutaci√≥n: cambia un car√°cter aleatoriamente en el individuo
    def mutate(individual, mutation_rate):
        individual = list(individual)
        for i in range(len(individual)):
            if np.random.rand() < mutation_rate:
                individual[i] = np.random.choice(alphabet)
        return ''.join(individual)

    # Evoluci√≥n de la poblaci√≥n
    def evolve_population(population, target_word, mutation_rate):
        selected = selection(population, target_word)
        children = []
        while len(children) < len(population):
            parent1, parent2 = np.random.choice(selected, 2, replace=False)
            child = crossover(parent1, parent2)
            child = mutate(child, mutation_rate)
            children.append(child)
        return children

    # Bot√≥n para iniciar la simulaci√≥n
    if st.button("Ejecutar Algoritmo Gen√©tico"):
        # Generaci√≥n inicial
        population = generate_population(population_size, word_length)
        best_match = ""
        for generation in range(num_generations):
            # Evoluci√≥n de la poblaci√≥n
            population = evolve_population(population, target_word, mutation_rate)
            best_match = max(population, key=lambda ind: fitness(ind, target_word))
            
            # Imprimir cada N generaciones
            if (generation + 1) % print_every == 0:
                st.write(f"**Generaci√≥n {generation + 1}:** Mejor combinaci√≥n encontrada: `{best_match}` - Aptitud: {fitness(best_match, target_word)}")

            # Condici√≥n de parada si encontramos la palabra objetivo
            if best_match == target_word:
                st.success(f"¬°La palabra objetivo '{target_word}' fue encontrada en la generaci√≥n {generation + 1}!")
                break
        else:
            st.warning("El algoritmo no logr√≥ encontrar la palabra objetivo en el n√∫mero de generaciones especificado.")

        # Mostrar el mejor resultado final si no se alcanz√≥ el objetivo
        if best_match != target_word:
            st.write(f"**Mejor combinaci√≥n final** despu√©s de {num_generations} generaciones: `{best_match}` - Aptitud: {fitness(best_match, target_word)}")
